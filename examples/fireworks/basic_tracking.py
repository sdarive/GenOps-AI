#!/usr/bin/env python3
"""
Fireworks AI Basic Tracking with GenOps Governance

Demonstrates basic Fireworks AI operations with automatic cost tracking and governance.
Perfect starting point for integrating Fireworks AI with GenOps governance controls.

Usage:
    python basic_tracking.py

Features:
    - Simple chat completions with cost tracking and 4x faster inference
    - Automatic governance attribute collection
    - Budget awareness and cost alerts
    - Multiple model comparisons across pricing tiers
    - Session-based operation tracking
"""

import os
import sys
from decimal import Decimal

try:
    from genops.providers.fireworks import GenOpsFireworksAdapter, FireworksModel
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("Please install GenOps: pip install genops-ai[fireworks]")
    sys.exit(1)


def main():
    """Demonstrate basic Fireworks AI tracking with GenOps."""
    print("ğŸ”¥ Fireworks AI Basic Tracking with GenOps")
    print("=" * 50)
    
    # Initialize adapter with governance configuration
    adapter = GenOpsFireworksAdapter(
        team=os.getenv('GENOPS_TEAM', 'demo-team'),
        project=os.getenv('GENOPS_PROJECT', 'basic-tracking'),
        environment=os.getenv('GENOPS_ENVIRONMENT', 'development'),
        daily_budget_limit=50.0,  # $50 daily budget
        monthly_budget_limit=1000.0,  # $1000 monthly budget
        enable_governance=True,
        enable_cost_alerts=True,
        governance_policy='advisory',  # Won't block operations, just warns
        default_model=FireworksModel.LLAMA_3_1_8B_INSTRUCT  # Cost-effective default
    )
    
    print("âœ… GenOps Fireworks adapter initialized")
    print(f"   Team: {adapter.team}")
    print(f"   Project: {adapter.project}")
    print(f"   Daily budget: ${adapter.daily_budget_limit}")
    
    # Example 1: Simple chat completion with basic governance
    print("\n" + "=" * 50)
    print("ğŸ”¥ Example 1: Basic Chat Completion (Fast Inference)")
    print("=" * 50)
    
    try:
        messages = [
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": "Explain what makes Fireworks AI unique in 2-3 sentences."}
        ]
        
        result = adapter.chat_with_governance(
            messages=messages,
            model=FireworksModel.LLAMA_3_1_8B_INSTRUCT,
            max_tokens=150,
            temperature=0.7,
            # Governance attributes
            feature="basic-demo",
            use_case="model-explanation"
        )
        
        print("ğŸ¯ Response:")
        print(f"   {result.response}")
        print(f"\nğŸ“Š Metrics:")
        print(f"   Model: {result.model_used.split('/')[-1]}")
        print(f"   Tokens: {result.tokens_used}")
        print(f"   Cost: ${result.cost:.6f}")
        print(f"   Speed: {result.execution_time_seconds:.2f}s (ğŸ”¥ Fireattention optimized!)")
        
    except Exception as e:
        print(f"âŒ Chat completion failed: {e}")
        return 1
    
    # Example 2: Compare multiple models across pricing tiers
    print("\n" + "=" * 50)
    print("ğŸ”¬ Example 2: Model Comparison Across Tiers")
    print("=" * 50)
    
    models_to_test = [
        (FireworksModel.LLAMA_3_2_1B_INSTRUCT, "Tiny tier"),      # $0.10/M
        (FireworksModel.LLAMA_3_1_8B_INSTRUCT, "Small tier"),     # $0.20/M  
        (FireworksModel.LLAMA_3_1_70B_INSTRUCT, "Large tier"),    # $0.90/M
        (FireworksModel.MIXTRAL_8X7B, "MoE tier")                 # $0.50/M
    ]
    
    question = "What are the main benefits of fast AI inference?"
    messages = [{"role": "user", "content": question}]
    
    model_results = []
    
    for model, tier_name in models_to_test:
        try:
            print(f"\nğŸ§  Testing {model.value.split('/')[-1]} ({tier_name})...")
            
            result = adapter.chat_with_governance(
                messages=messages,
                model=model,
                max_tokens=100,
                temperature=0.5,
                # Track which model comparison this is
                comparison_batch="model-comparison",
                model_tier=tier_name
            )
            
            model_results.append(result)
            print(f"   âœ… Response length: {len(result.response)} chars")
            print(f"   ğŸ’° Cost: ${result.cost:.6f}")
            print(f"   âš¡ Speed: {result.execution_time_seconds:.2f}s")
            
        except Exception as e:
            print(f"   âŒ Failed: {e}")
            continue
    
    # Compare results
    if model_results:
        print(f"\nğŸ“Š Model Comparison Summary:")
        total_cost = sum(r.cost for r in model_results)
        avg_time = sum(r.execution_time_seconds for r in model_results) / len(model_results)
        
        print(f"   Models tested: {len(model_results)}")
        print(f"   Total cost: ${total_cost:.6f}")
        print(f"   Average speed: {avg_time:.2f}s")
        
        # Find most cost-effective
        cheapest = min(model_results, key=lambda x: x.cost)
        print(f"   Most cost-effective: {cheapest.model_used.split('/')[-1]} (${cheapest.cost:.6f})")
        
        # Find fastest (should all be fast with Fireattention)
        fastest = min(model_results, key=lambda x: x.execution_time_seconds)
        print(f"   Fastest: {fastest.model_used.split('/')[-1]} ({fastest.execution_time_seconds:.2f}s)")
    
    # Example 3: Session-based tracking with different models
    print("\n" + "=" * 50)
    print("ğŸ¯ Example 3: Session-Based Multi-Model Tracking")
    print("=" * 50)
    
    try:
        # Use session context manager for related operations
        with adapter.track_session(
            "creative-writing",
            customer_id="demo-customer",
            use_case="content-generation"
        ) as session:
            
            print(f"ğŸ“‹ Started session: {session.session_name}")
            print(f"   Session ID: {session.session_id}")
            
            # Multiple related operations with different models
            creative_tasks = [
                ("Write a haiku about fast AI inference", FireworksModel.LLAMA_3_1_8B_INSTRUCT),
                ("Create a story opening about lightning-fast robots", FireworksModel.LLAMA_3_1_70B_INSTRUCT),
                ("Generate creative names for a speed-focused AI company", FireworksModel.MIXTRAL_8X7B)
            ]
            
            session_results = []
            for i, (prompt, model) in enumerate(creative_tasks, 1):
                print(f"\n   ğŸ“ Operation {i}/{len(creative_tasks)} with {model.value.split('/')[-1]}")
                
                result = adapter.chat_with_governance(
                    messages=[{"role": "user", "content": prompt}],
                    model=model,
                    max_tokens=80,
                    session_id=session.session_id,
                    operation_index=i
                )
                
                session_results.append(result)
                print(f"      Response: {result.response[:60]}...")
                print(f"      Cost: ${result.cost:.6f}")
                print(f"      Speed: {result.execution_time_seconds:.2f}s")
            
            print(f"\nğŸ“Š Session Summary:")
            print(f"   Total operations: {session.total_operations}")
            print(f"   Total cost: ${session.total_cost:.6f}")
            print(f"   Average cost/operation: ${session.total_cost / len(session_results):.6f}")
            print(f"   Average speed: {sum(r.execution_time_seconds for r in session_results) / len(session_results):.2f}s")
    
    except Exception as e:
        print(f"âŒ Session tracking failed: {e}")
        return 1
    
    # Example 4: Multimodal operations (if supported)
    print("\n" + "=" * 50)
    print("ğŸ‘ï¸ Example 4: Multimodal Capabilities")
    print("=" * 50)
    
    try:
        # Embedding example
        embedding_result = adapter.embeddings_with_governance(
            input_texts=["Fast AI inference is revolutionary", "Fireworks AI provides 4x speed improvements"],
            model=FireworksModel.NOMIC_EMBED_TEXT,
            feature="text-embedding",
            use_case="semantic-similarity"
        )
        
        print("ğŸ”¤ Text Embeddings:")
        print(f"   Embedded 2 texts")
        print(f"   Cost: ${embedding_result.cost:.6f}")
        print(f"   Speed: {embedding_result.execution_time_seconds:.2f}s")
        
    except Exception as e:
        print(f"âš ï¸ Multimodal example skipped: {e}")
    
    # Show overall cost summary
    print("\n" + "=" * 50)
    print("ğŸ’° Cost Summary")
    print("=" * 50)
    
    cost_summary = adapter.get_cost_summary()
    print(f"Daily spending: ${cost_summary['daily_costs']:.6f}")
    print(f"Budget utilization: {cost_summary['daily_budget_utilization']:.1f}%")
    print(f"Operations completed: {len(model_results) + len(session_results) + 1}")
    
    if cost_summary['daily_budget_utilization'] > 50:
        print("âš ï¸  High budget utilization - consider cost optimization")
    else:
        print("âœ… Spending within comfortable limits")
    
    print("\nğŸ‰ Basic tracking demonstration completed!")
    print("\nğŸš€ Next Steps:")
    print("   â€¢ Try cost_optimization.py for intelligent model selection")
    print("   â€¢ Run advanced_features.py for multimodal and streaming")
    print("   â€¢ Explore production_patterns.py for enterprise patterns")
    print("   â€¢ Enjoy 4x faster inference with Fireworks AI! ğŸ”¥")
    
    return 0


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Demo interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        print("Try running setup_validation.py to check your configuration")
        sys.exit(1)