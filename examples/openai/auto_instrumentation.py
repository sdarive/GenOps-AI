#!/usr/bin/env python3
"""
OpenAI Auto-Instrumentation Example

This example demonstrates GenOps zero-code auto-instrumentation for OpenAI.
Your existing OpenAI code works unchanged, but gets automatic governance telemetry.

What you'll learn:
- Zero-code setup with auto_instrument()
- Governance context for cost attribution
- Transparent telemetry with no API changes

Usage:
    python auto_instrumentation.py
    
Prerequisites:
    pip install genops-ai[openai]
    export OPENAI_API_KEY="your_api_key_here"
"""

import os
import sys

def setup_auto_instrumentation():
    """Set up GenOps auto-instrumentation for OpenAI."""
    print("üîß Setting Up Auto-Instrumentation")
    print("-" * 40)
    
    try:
        # This single line enables automatic telemetry for ALL OpenAI operations
        from genops import auto_instrument
        auto_instrument()
        
        print("‚úÖ GenOps auto-instrumentation enabled!")
        print("   ‚Ä¢ All OpenAI operations will automatically include telemetry")
        print("   ‚Ä¢ No changes to your existing OpenAI code required")
        print("   ‚Ä¢ Cost and performance data automatically captured")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("üí° Fix: Run 'pip install genops-ai[openai]'")
        return False

def existing_openai_code_unchanged():
    """Your existing OpenAI code works exactly as before, but with automatic telemetry."""
    print("\n\nüíª Your Existing OpenAI Code (Unchanged)")
    print("-" * 50)
    
    try:
        # This is your normal OpenAI code - no changes needed!
        from openai import OpenAI
        
        client = OpenAI()  # Uses OPENAI_API_KEY from environment
        
        print("üöÄ Making standard OpenAI requests...")
        
        # Example 1: Simple chat completion (your existing code)
        response1 = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "What is machine learning?"}
            ],
            max_tokens=100
        )
        
        print(f"‚úÖ Response 1: {response1.choices[0].message.content[:50]}...")
        
        # Example 2: More complex completion (your existing code)
        response2 = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful data scientist."},
                {"role": "user", "content": "Explain the bias-variance tradeoff"}
            ],
            temperature=0.7,
            max_tokens=200
        )
        
        print(f"‚úÖ Response 2: {response2.choices[0].message.content[:50]}...")
        
        # Example 3: Legacy completion endpoint (if you use it)
        try:
            response3 = client.completions.create(
                model="gpt-3.5-turbo-instruct",
                prompt="Write a haiku about programming:",
                max_tokens=50
            )
            print(f"‚úÖ Response 3: {response3.choices[0].text.strip()[:50]}...")
        except Exception as e:
            print(f"‚ÑπÔ∏è  Legacy completions skipped: {e}")
        
        print("\nüéØ Key Point: Zero code changes, automatic telemetry!")
        print("   ‚Ä¢ All requests above were automatically tracked")
        print("   ‚Ä¢ Cost calculations performed automatically")  
        print("   ‚Ä¢ Performance metrics captured automatically")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error with existing OpenAI code: {e}")
        print("üí° Check your OPENAI_API_KEY and network connectivity")
        return False

def add_governance_context():
    """Add governance context to automatically apply to all operations."""
    print("\n\nüè∑Ô∏è  Adding Governance Context")
    print("-" * 40)
    
    try:
        from genops.core.context import set_governance_context
        from openai import OpenAI
        
        # Set governance context once - applies to ALL subsequent operations
        set_governance_context({
            "team": "auto-instrumentation-demo",
            "project": "genops-examples",
            "customer_id": "demo-customer-auto",
            "environment": "development",
            "cost_center": "engineering-dept"
        })
        
        print("‚úÖ Governance context set for all operations:")
        print("   ‚Ä¢ team: auto-instrumentation-demo")
        print("   ‚Ä¢ project: genops-examples")
        print("   ‚Ä¢ customer_id: demo-customer-auto")
        print("   ‚Ä¢ environment: development")
        
        # Now all OpenAI operations automatically inherit these attributes
        client = OpenAI()
        
        print("\nüöÄ Making requests with automatic governance attribution...")
        
        # These requests automatically get the governance context above
        tasks = [
            "Explain quantum computing briefly",
            "What are the benefits of renewable energy?",
            "How do neural networks learn?"
        ]
        
        for i, task in enumerate(tasks, 1):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": task}],
                max_tokens=50
            )
            
            print(f"   {i}. Task: {task}")
            print(f"      Response: {response.choices[0].message.content[:40]}...")
        
        print("\nüí∞ All costs automatically attributed to:")
        print("   ‚Ä¢ Team: auto-instrumentation-demo")  
        print("   ‚Ä¢ Project: genops-examples")
        print("   ‚Ä¢ Customer: demo-customer-auto")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Error setting governance context: {e}")
        return False

def web_application_pattern():
    """Demonstrate auto-instrumentation in web application context."""
    print("\n\nüåê Web Application Integration Pattern")
    print("-" * 50)
    
    try:
        from genops.core.context import set_governance_context
        from openai import OpenAI
        
        # Simulate web application request handler
        def handle_chat_request(user_id: str, message: str, session_id: str):
            """Simulated web app request handler with automatic telemetry."""
            
            # Set request-specific governance context
            set_governance_context({
                "team": "web-app-team",
                "project": "customer-chat-api", 
                "customer_id": user_id,
                "environment": "production",
                "feature": "chat-endpoint",
                "session_id": session_id
            })
            
            # Your normal OpenAI code - completely unchanged
            client = OpenAI()
            response = client.chat.completions.create(
                model="gpt-3.5-turbo", 
                messages=[
                    {"role": "system", "content": "You are a helpful customer service assistant."},
                    {"role": "user", "content": message}
                ],
                max_tokens=150
            )
            
            return response.choices[0].message.content
        
        # Simulate multiple user requests
        print("üîÑ Simulating web application requests...")
        
        simulated_requests = [
            ("user-001", "How do I reset my password?", "session-abc-123"),
            ("user-002", "What are your business hours?", "session-def-456"), 
            ("user-003", "I need help with billing", "session-ghi-789")
        ]
        
        for user_id, message, session_id in simulated_requests:
            response = handle_chat_request(user_id, message, session_id)
            print(f"   User {user_id}: {message}")
            print(f"   Response: {response[:60]}...")
            print()
        
        print("‚úÖ Web application pattern complete!")
        print("üí° Each request automatically gets:")
        print("   ‚Ä¢ User-specific cost attribution")
        print("   ‚Ä¢ Session tracking") 
        print("   ‚Ä¢ Feature-level cost allocation")
        print("   ‚Ä¢ Environment and team attribution")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Web application pattern error: {e}")
        return False

def main():
    """Run auto-instrumentation demonstration."""
    print("ü§ñ GenOps OpenAI Auto-Instrumentation Demo")
    print("=" * 60)
    
    # Check prerequisites
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå OPENAI_API_KEY environment variable not set")
        print("üí° Fix: export OPENAI_API_KEY='your_api_key_here'")
        return False
    
    success = True
    
    # Run demonstrations
    success &= setup_auto_instrumentation()
    success &= existing_openai_code_unchanged()
    success &= add_governance_context()
    success &= web_application_pattern()
    
    # Summary
    print("\n" + "=" * 60)
    if success:
        print("üéâ Auto-instrumentation demonstration complete!")
        
        print("\nüîë Key Takeaways:")
        print("   ‚úÖ One line enables telemetry: auto_instrument()")
        print("   ‚úÖ Zero changes to existing OpenAI code")
        print("   ‚úÖ Automatic cost calculation and attribution")
        print("   ‚úÖ Governance context applies to all operations")
        print("   ‚úÖ Perfect for web applications and microservices")
        
        print("\nüí∞ Benefits:")
        print("   ‚Ä¢ Instant cost visibility across all OpenAI usage")
        print("   ‚Ä¢ Automatic attribution to teams, projects, customers")
        print("   ‚Ä¢ No code refactoring or API changes required")
        print("   ‚Ä¢ Drop-in replacement for existing applications")
        
        print("\nüöÄ Next Steps:")
        print("   ‚Ä¢ Run 'python cost_optimization.py' for multi-model strategies")
        print("   ‚Ä¢ Try 'python advanced_features.py' for streaming and functions")
        print("   ‚Ä¢ Explore 'python production_patterns.py' for enterprise patterns")
        
        return True
    else:
        print("‚ùå Auto-instrumentation demonstration failed.")
        print("üí° Check the error messages above and try setup_validation.py")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)