#!/usr/bin/env python3
"""
W&B Basic Tracking with GenOps Governance

This example demonstrates basic experiment tracking with Weights & Biases enhanced
with GenOps governance, cost intelligence, and team attribution.

Features demonstrated:
- Simple experiment tracking with W&B and GenOps
- Automatic cost attribution and team tracking
- Basic metrics logging with governance attributes
- Cost calculation and budget monitoring
- Team and project attribution for ML experiments

Usage:
    python basic_tracking.py

Prerequisites:
    pip install genops[wandb]
    export WANDB_API_KEY="your-wandb-api-key"
    export GENOPS_TEAM="your-team"      # Optional but recommended
    export GENOPS_PROJECT="your-project" # Optional but recommended

This example runs a simple ML training simulation with W&B tracking and
GenOps governance to demonstrate the basic integration patterns.
"""

import os
import time
import random
import numpy as np
from datetime import datetime


def simulate_realistic_ml_training(model_config):
    """
    Simulate a realistic ML training process with proper convergence curves.
    
    This simulates training a neural network for image classification with
    realistic training dynamics including:
    - Learning rate decay
    - Validation metrics
    - Early stopping potential
    - Realistic convergence behavior
    """
    print("ðŸ§  Simulating realistic neural network training...")
    print(f"   â€¢ Model: {model_config.get('model_type', 'neural_network')}")
    print(f"   â€¢ Dataset: CIFAR-10 (simulated)")
    print(f"   â€¢ Optimizer: {model_config.get('optimizer', 'adam')}")
    print(f"   â€¢ Initial LR: {model_config.get('learning_rate', 0.001)}")
    
    # Model complexity affects convergence
    model_complexity = {
        'simple_cnn': {'base_acc': 0.75, 'convergence_rate': 0.8, 'cost_per_epoch': 0.08},
        'resnet18': {'base_acc': 0.85, 'convergence_rate': 0.6, 'cost_per_epoch': 0.12},
        'resnet50': {'base_acc': 0.88, 'convergence_rate': 0.4, 'cost_per_epoch': 0.18},
        'neural_network': {'base_acc': 0.80, 'convergence_rate': 0.7, 'cost_per_epoch': 0.10}
    }
    
    model_type = model_config.get('model_type', 'neural_network')
    model_props = model_complexity.get(model_type, model_complexity['neural_network'])
    
    # Training parameters
    epochs = model_config.get('epochs', 10)
    initial_lr = model_config.get('learning_rate', 0.001)
    batch_size = model_config.get('batch_size', 32)
    
    # Simulate dataset splits
    train_samples = 45000  # CIFAR-10 training set
    val_samples = 5000     # CIFAR-10 validation set
    steps_per_epoch = train_samples // batch_size
    
    print(f"   â€¢ Training samples: {train_samples:,}")
    print(f"   â€¢ Validation samples: {val_samples:,}")
    print(f"   â€¢ Steps per epoch: {steps_per_epoch}")
    print()
    
    # Initialize metrics tracking
    best_val_acc = 0.0
    patience_counter = 0
    patience_limit = 3
    
    for epoch in range(epochs):
        print(f"   ðŸ“ˆ Epoch {epoch + 1}/{epochs}")
        
        # Learning rate decay
        current_lr = initial_lr * (0.95 ** epoch)  # 5% decay per epoch
        
        # Simulate realistic training progression
        progress = (epoch + 1) / epochs
        base_accuracy = model_props['base_acc']
        convergence_rate = model_props['convergence_rate']
        
        # Training accuracy (usually higher than validation)
        train_acc_gain = (base_accuracy * 0.25) * (1 - np.exp(-3 * progress * convergence_rate))
        train_accuracy = base_accuracy + train_acc_gain + random.uniform(-0.015, 0.015)
        
        # Validation accuracy (more conservative, the real metric)
        val_acc_gain = (base_accuracy * 0.2) * (1 - np.exp(-2.5 * progress * convergence_rate))
        val_accuracy = base_accuracy + val_acc_gain + random.uniform(-0.025, 0.025)
        
        # Ensure validation is typically lower than training (overfitting simulation)
        if val_accuracy > train_accuracy:
            val_accuracy = train_accuracy - random.uniform(0.01, 0.03)
        
        # Calculate losses (inversely related to accuracy)
        train_loss = max(0.02, 2.5 * (1 - train_accuracy) + random.uniform(-0.1, 0.1))
        val_loss = max(0.02, 2.5 * (1 - val_accuracy) + random.uniform(-0.05, 0.15))
        
        # Clamp to realistic ranges
        train_accuracy = max(0.1, min(0.99, train_accuracy))
        val_accuracy = max(0.1, min(0.99, val_accuracy))
        
        # Calculate epoch cost based on model complexity and batch size
        base_cost = model_props['cost_per_epoch']
        batch_factor = batch_size / 32  # Cost scales with batch size
        epoch_cost = base_cost * batch_factor + random.uniform(-0.01, 0.01)
        epoch_cost = max(0.02, epoch_cost)  # Minimum cost
        
        # Simulate GPU utilization and memory usage
        gpu_util = random.uniform(85, 98)  # High GPU utilization during training
        gpu_memory = random.uniform(6.2, 7.8)  # GB memory usage
        
        # Early stopping logic
        if val_accuracy > best_val_acc:
            best_val_acc = val_accuracy
            patience_counter = 0
            improved = True
        else:
            patience_counter += 1
            improved = False
        
        # Detailed progress output
        print(f"      Train: acc={train_accuracy:.4f}, loss={train_loss:.4f}")
        print(f"      Val:   acc={val_accuracy:.4f}, loss={val_loss:.4f}")
        print(f"      LR: {current_lr:.6f}, Cost: ${epoch_cost:.3f}")
        print(f"      GPU: {gpu_util:.1f}% util, {gpu_memory:.1f}GB mem")
        if improved:
            print(f"      âœ¨ New best validation accuracy!")
        print()
        
        # Yield comprehensive metrics
        yield {
            'epoch': epoch,
            'train_accuracy': train_accuracy,
            'train_loss': train_loss,
            'val_accuracy': val_accuracy,
            'val_loss': val_loss,
            'learning_rate': current_lr,
            'epoch_cost': epoch_cost,
            'gpu_utilization': gpu_util,
            'gpu_memory_gb': gpu_memory,
            'best_val_acc': best_val_acc,
            'patience': patience_counter,
            'steps_per_epoch': steps_per_epoch,
            'improved': improved
        }
        
        # Early stopping check
        if patience_counter >= patience_limit and epoch >= 5:  # Allow at least 5 epochs
            print(f"      ðŸ›‘ Early stopping triggered (patience={patience_limit})")
            break
        
        # Simulate training time
        time.sleep(0.15)  # Slightly longer for realism
    
    return {
        'best_val_accuracy': best_val_acc,
        'final_train_accuracy': train_accuracy,
        'total_epochs_run': epoch + 1,
        'early_stopped': patience_counter >= patience_limit,
        'model_complexity': model_props
    }


def main():
    """Main function demonstrating basic W&B tracking with GenOps governance."""
    print("ðŸ”¬ W&B Basic Tracking with GenOps Governance")
    print(f"ðŸ•’ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Check prerequisites
    api_key = os.getenv('WANDB_API_KEY')
    if not api_key:
        print("âŒ WANDB_API_KEY environment variable not set")
        print("ðŸ’¡ Get your API key from https://wandb.ai/settings")
        print("   export WANDB_API_KEY='your-api-key'")
        return False
    
    team = os.getenv('GENOPS_TEAM', 'demo-team')
    project = os.getenv('GENOPS_PROJECT', 'basic-tracking-demo')
    
    print(f"ðŸ“‹ Configuration:")
    print(f"   â€¢ Team: {team}")
    print(f"   â€¢ Project: {project}")
    print(f"   â€¢ API Key: {'âœ… Set' if api_key else 'âŒ Not set'}")
    print()
    
    try:
        # Import required modules
        import wandb
        from genops.providers.wandb import instrument_wandb
        
        print("âœ… Successfully imported W&B and GenOps modules")
        
        # Create GenOps W&B adapter
        print("\nðŸ”§ Creating GenOps W&B adapter...")
        adapter = instrument_wandb(
            wandb_api_key=api_key,
            team=team,
            project=project,
            daily_budget_limit=5.0,  # $5 daily budget for demo
            max_experiment_cost=2.0,  # $2 max per experiment
            enable_cost_alerts=True,
            enable_governance=True
        )
        
        print("âœ… GenOps W&B adapter created successfully")
        
        # Display initial metrics
        initial_metrics = adapter.get_metrics()
        print(f"\nðŸ“Š Initial Governance Metrics:")
        print(f"   â€¢ Daily Budget: ${initial_metrics['daily_budget_limit']:.2f}")
        print(f"   â€¢ Budget Remaining: ${initial_metrics['budget_remaining']:.2f}")
        print(f"   â€¢ Governance Policy: {initial_metrics['governance_policy']}")
        print(f"   â€¢ Team: {initial_metrics['team']}")
        print(f"   â€¢ Project: {initial_metrics['project']}")
        
        # Start W&B experiment with governance
        print("\nðŸš€ Starting W&B experiment with GenOps tracking...")
        
        experiment_config = {
            'model_type': 'neural_network',
            'optimizer': 'adam',
            'learning_rate': 0.001,
            'batch_size': 32,
            'epochs': 10
        }
        
        # Track experiment lifecycle with governance
        with adapter.track_experiment_lifecycle(
            experiment_name="basic-ml-training",
            experiment_type="training",
            max_cost=2.0
        ) as experiment:
            
            # Initialize W&B run
            run = wandb.init(
                project=f"genops-{project}",
                name="basic-tracking-demo",
                config=experiment_config,
                tags=["demo", "basic", "genops"]
            )
            
            print(f"   â€¢ W&B Run ID: {run.id}")
            print(f"   â€¢ W&B Project: {run.project}")
            print(f"   â€¢ Experiment ID: {experiment.run_id}")
            
            # Log initial configuration
            run.log({
                'genops_team': team,
                'genops_project': project,
                'genops_experiment_cost': 0.0
            })
            
            # Run realistic training simulation with comprehensive metrics
            print("\nðŸƒ Running realistic training simulation...")
            total_cost = 0.0
            training_metrics = []
            
            for metrics in simulate_realistic_ml_training(experiment_config):
                # Log comprehensive metrics to W&B
                wandb_metrics = {
                    'epoch': metrics['epoch'],
                    'train_accuracy': metrics['train_accuracy'],
                    'train_loss': metrics['train_loss'],
                    'val_accuracy': metrics['val_accuracy'],
                    'val_loss': metrics['val_loss'],
                    'learning_rate': metrics['learning_rate'],
                    'gpu_utilization': metrics['gpu_utilization'],
                    'gpu_memory_gb': metrics['gpu_memory_gb'],
                    'best_val_acc': metrics['best_val_acc'],
                    'patience': metrics['patience'],
                    'steps_per_epoch': metrics['steps_per_epoch']
                }
                
                run.log(wandb_metrics)
                
                # Track epoch cost
                epoch_cost = metrics['epoch_cost']
                total_cost += epoch_cost
                training_metrics.append(metrics)
                
                # Update experiment cost in governance
                experiment.estimated_cost += epoch_cost
                
                # Check for governance violations
                if experiment.estimated_cost > 1.8:  # Approaching limit
                    print(f"   âš ï¸ Approaching cost limit: ${experiment.estimated_cost:.3f}")
                    
                # Check if training was stopped early
                if metrics['epoch'] >= 4 and metrics['patience'] >= 3:  # Early stopping triggered
                    print(f"   ðŸ›‘ Training stopped early due to lack of improvement")
                    break
            
            # Calculate final experiment metrics from realistic training
            if training_metrics:
                final_metrics = training_metrics[-1]  # Last epoch metrics
                final_accuracy = final_metrics['val_accuracy']
                final_loss = final_metrics['val_loss']
                best_accuracy = final_metrics['best_val_acc']
                total_epochs = final_metrics['epoch'] + 1
            else:
                # Fallback if no training occurred
                final_accuracy = 0.5
                final_loss = 1.0
                best_accuracy = 0.5
                total_epochs = 0
            
            # Log final comprehensive metrics
            run.log({
                'final_val_accuracy': final_accuracy,
                'final_val_loss': final_loss,
                'best_val_accuracy': best_accuracy,
                'total_epochs': total_epochs,
                'total_cost': total_cost,
                'cost_per_epoch': total_cost / max(total_epochs, 1),
                'cost_efficiency': best_accuracy / max(total_cost, 0.01),
                'early_stopped': total_epochs < experiment_config['epochs']
            })
            
            # Create a simple artifact for demonstration
            artifact = wandb.Artifact("model-weights", type="model")
            
            # Simulate saving model weights with realistic training results
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                f.write(f"Model weights for validation accuracy: {final_accuracy:.4f}\n")
                f.write(f"Best validation accuracy achieved: {best_accuracy:.4f}\n")
                f.write(f"Training completed after {total_epochs} epochs\n")
                f.write(f"Training cost: ${total_cost:.3f}\n")
                f.write(f"Cost efficiency: {best_accuracy / max(total_cost, 0.01):.2f} accuracy/dollar\n")
                model_file = f.name
            
            artifact.add_file(model_file)
            
            # Log artifact with governance
            adapter.log_governed_artifact(
                artifact=artifact,
                cost_estimate=0.01,  # $0.01 for artifact storage
                governance_metadata={
                    'final_val_accuracy': final_accuracy,
                    'best_val_accuracy': best_accuracy,
                    'total_epochs_trained': total_epochs,
                    'training_cost': total_cost,
                    'cost_efficiency': best_accuracy / max(total_cost, 0.01),
                    'early_stopped': total_epochs < experiment_config['epochs']
                }
            )
            
            print(f"\nðŸ’¾ Logged model artifact with governance metadata")
            
            # Update final experiment cost
            experiment.estimated_cost = total_cost + 0.01  # Include artifact cost
            
            # Finish W&B run
            run.finish()
            
            print(f"\nâœ… Realistic ML experiment completed successfully!")
            print(f"   â€¢ Final Cost: ${experiment.estimated_cost:.3f}")
            print(f"   â€¢ Best Validation Accuracy: {best_accuracy:.4f}")
            print(f"   â€¢ Final Validation Accuracy: {final_accuracy:.4f}")
            print(f"   â€¢ Epochs Completed: {total_epochs}/{experiment_config['epochs']}")
            if total_epochs < experiment_config['epochs']:
                print(f"   â€¢ Early Stopped: Yes (patience limit reached)")
            print(f"   â€¢ Cost Efficiency: {best_accuracy / max(total_cost, 0.01):.2f} accuracy/dollar")
        
        # Display final governance metrics
        final_metrics = adapter.get_metrics()
        print(f"\nðŸ“Š Final Governance Metrics:")
        print(f"   â€¢ Daily Usage: ${final_metrics['daily_usage']:.3f}")
        print(f"   â€¢ Budget Remaining: ${final_metrics['budget_remaining']:.3f}")
        print(f"   â€¢ Total Operations: {final_metrics['operation_count']}")
        print(f"   â€¢ Active Experiments: {final_metrics['active_experiments']}")
        
        # Get experiment cost summary
        experiment_summary = adapter.get_experiment_cost_summary(experiment.run_id)
        if experiment_summary:
            print(f"\nðŸ’° Experiment Cost Breakdown:")
            print(f"   â€¢ Total Cost: ${experiment_summary.total_cost:.3f}")
            print(f"   â€¢ Compute Cost: ${experiment_summary.compute_cost:.3f}")
            print(f"   â€¢ Storage Cost: ${experiment_summary.storage_cost:.3f}")
            print(f"   â€¢ Duration: {experiment_summary.experiment_duration / 60:.1f} minutes")
            print(f"   â€¢ Efficiency: ${experiment_summary.resource_efficiency:.3f}/hour")
        
        print("\nðŸŽ‰ Basic tracking with governance completed successfully!")
        print("\nðŸ“š What happened:")
        print("   âœ… Created GenOps W&B adapter with governance policies")
        print("   âœ… Tracked ML experiment with automatic cost attribution")
        print("   âœ… Logged metrics, artifacts, and governance metadata")
        print("   âœ… Monitored budget limits and governance compliance")
        print("   âœ… Generated cost breakdown and efficiency analysis")
        
        print("\nðŸš€ Next Steps:")
        print("   â€¢ Try auto-instrumentation: python auto_instrumentation.py")
        print("   â€¢ Explore experiment management: python experiment_management.py")
        print("   â€¢ Learn cost optimization: python cost_optimization.py")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("ðŸ’¡ Install required packages: pip install genops[wandb]")
        return False
        
    except Exception as e:
        print(f"âŒ Error during execution: {e}")
        print("ðŸ’¡ Check your configuration and try running setup_validation.py first")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)